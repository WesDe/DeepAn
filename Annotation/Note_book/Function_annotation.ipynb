{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import matplotlib.mlab as mlab \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import pandas as pd\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import statistics\n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_size_align(a,b) :\n",
    "    size=0\n",
    "    if a > b :\n",
    "        size =a-b\n",
    "    else :\n",
    "        size =b-a\n",
    "    return size\n",
    "def check_presence(elt,dic):\n",
    "    if elt in dic :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "def check_duplication(info_file,threshold,dic_occurrence): \n",
    "    inpt=csv.reader(open(info_file,\"r\"),delimiter=\"\\t\")\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    count=0\n",
    "    seen_validate=set()\n",
    "    dic=defaultdict(list)\n",
    "    dic_last=defaultdict(float)\n",
    "    black_list=[]\n",
    "    dic_segm=defaultdict(float)\n",
    "    dic_td=defaultdict(float)\n",
    "    dic_not_valid=defaultdict(float)\n",
    "    count_td=0\n",
    "    liste_segm_dup=[]\n",
    "    count_segm=0\n",
    "    dic_tes=defaultdict(list)\n",
    "    for elt in inpt :\n",
    "        if len(elt[9].split(\"_\"))<=4 :\n",
    "            match=int(elt[0])\n",
    "            size_align=check_size_align(int(elt[12]),int(elt[11]))\n",
    "            size_align_ref=check_size_align(int(elt[16]),int(elt[15]))\n",
    "            size_inser=int(elt[9].split(\"_\")[-1])\n",
    "            chrom_inser=re.sub(\"chr\", \"\",elt[9].split(\"_\")[0])\n",
    "            inser_pos=int(elt[9].split(\"_\")[2])\n",
    "            chrom_ref=re.sub(\"chr\", \"\",elt[13])\n",
    "            ref_pos=int(elt[15])\n",
    "            head=chrom_inser+\"_\"+str(inser_pos)+\"_\"+str(size_inser)\n",
    "            #print(head)\n",
    "            #print(size_align,size_istsnser,chrom_inser,inser_pos,chrom_ref,ref_pos)\n",
    "            #percentage=float(size_align/size_inser)\n",
    "            percentage=float(match/size_inser)\n",
    "            #print(percentage)\n",
    "            if chrom_ref==chrom_inser and ref_pos>=inser_pos-size_inser and ref_pos<=inser_pos+size_inser :\n",
    "                #print(elt)\n",
    "                black_list.append(head)\n",
    "            dic[head].append(percentage)\n",
    "            #if head in dic_occurrence and size_inser>=1000 and head not in liste_segm_dup and dic_occurrence[head]>=1 and dic_occurrence[head]<=50 :\n",
    "            #    liste_segm_dup.append(head)\n",
    "            #    count_segm+=1\n",
    "            iden=elt[9]\n",
    "            size_align=elt[18].split(\",\")\n",
    "            size_inse=elt[19].split(\",\")\n",
    "            for i in range (0,len(size_align)-1):\n",
    "                couple=(int(size_inse[i]),int(size_inse[i])+int(size_align[i]))\n",
    "                dic_tes[iden].append(couple)\n",
    "    for elt in dic :\n",
    "        #print(elt)\n",
    "        best=max(dic[elt])\n",
    "        if elt not in black_list and elt not in liste_segm_dup and dic_occurrence[elt]<=50 and best >=threshold :\n",
    "                dic_last[elt]=best\n",
    "                seen_validate.add(elt)\n",
    "                count+=1\n",
    "        if elt in black_list and best >=threshold  and elt not in liste_segm_dup and best >=threshold :\n",
    "            dic_td[elt]=best\n",
    "            #seen_validate.add(elt)\n",
    "            count_td+=1\n",
    "        if elt in liste_segm_dup and best >=threshold :\n",
    "            dic_segm[elt]=best\n",
    "            \n",
    "        if elt not in liste_segm_dup  and best >=threshold :\n",
    "            dic_not_valid[elt]=best\n",
    "                #print(best,elt)\n",
    "            #print(best)\n",
    "        #break\n",
    "        #break\n",
    "    #for e in black_list :\n",
    "    #    if e in seen_validate :\n",
    "    #        seen_validate.remove(e)\n",
    "    #        count-=1\n",
    "    #print(count,count_td,count_segm,len(dic_not_valid))\n",
    "    return(dic_last,dic_td,dic_segm,dic_not_valid,dic_tes)\n",
    "\n",
    "def get_dic_composite(dic_tes):\n",
    "    dic_size_align=defaultdict()\n",
    "    for elt in dic_tes :\n",
    "        #print(\"before\",dic_tes[elt])\n",
    "        work_list=sorted(dic_tes[elt], key=lambda tup:tup[0]) \n",
    "        #print(\"after\",work_list)\n",
    "        size=0\n",
    "        st=0\n",
    "        for elts in work_list :\n",
    "            if st==0 :\n",
    "                begin=elts[0]\n",
    "                end=elts[1]\n",
    "                st+=1\n",
    "                continue\n",
    "            else :\n",
    "                if elts[1]>end and elts[0]<=end :\n",
    "                    end=elts[1]\n",
    "                elif elts[1]<=end or (elts[0]==begin and elts[1]==end):\n",
    "                    continue\n",
    "                elif elts[0]>end :\n",
    "                    size+=end-begin\n",
    "                    begin=elts[0]\n",
    "                    end=elts[1]\n",
    "                else :\n",
    "                    print(\"probleme\",elts,begin,end)\n",
    "        size+=end-begin\n",
    "        dic_size_align[elt]=size\n",
    "    return dic_size_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_db(info_file,threshold):\n",
    "    TRF=csv.reader(open(info_file,\"r\"),delimiter=\" \")\n",
    "    seen_validate=set()\n",
    "    dic=defaultdict(list)\n",
    "    #next(TRF)\n",
    "    count=0\n",
    "    dic_last=defaultdict(float)\n",
    "    dic_seed=defaultdict(list)\n",
    "    dic_seed_unique=defaultdict(list)\n",
    "    for elt in TRF :\n",
    "        #print(elt)\n",
    "        if len(elt[0].split(\"_\"))<=4 :\n",
    "            #print(elt)\n",
    "            size_trf =check_size_align(int(elt[2]),int(elt[1]))+1\n",
    "            parser=elt[0].split(\"_\")\n",
    "            chromosome=re.sub(\"chr\", \"\",parser[0])\n",
    "            position=int(parser[-2])\n",
    "            size=int(parser[-1])\n",
    "            percentage=float(size_trf)/float(size)\n",
    "            head=chromosome+\"_\"+str(position)+\"_\"+str(size)\n",
    "            #print (percentage)\n",
    "            if percentage >=threshold :\n",
    "                dic[head].append(percentage)\n",
    "                compound=(float(elt[3]),float(elt[4]))\n",
    "                dic_seed[head].append(compound)\n",
    "            \n",
    "    for elt in dic :\n",
    "        #print(dic[elt],elt)\n",
    "        best=max(dic[elt])\n",
    "        if best >=threshold :\n",
    "            dic_last[elt]=best\n",
    "            seen_validate.add(elt)\n",
    "            count+=1\n",
    "            #print(best)\n",
    "    for elt in dic_seed :\n",
    "        if len(dic_seed[elt])!=1 :\n",
    "            lower_seed=dic_seed[elt][0][0]\n",
    "            max_rep=dic_seed[elt][0][1]\n",
    "            for e in dic_seed[elt]:\n",
    "                if e[0]< lower_seed and e[1]>max_rep :\n",
    "                    lower_seed=e[0]\n",
    "                    max_rep=e[1]\n",
    "            dic_seed_unique[elt]=(lower_seed,max_rep)\n",
    "        else :\n",
    "            dic_seed_unique[elt]=(dic_seed[elt][0][0],dic_seed[elt][0][1])\n",
    "    print(count)\n",
    "    return(dic_last,dic_seed_unique)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validate_variant(vcf,dictionary,otp,otp_2) :\n",
    "    for elt in vcf :\n",
    "        #print(elt)\n",
    "        if \"#\" not in elt[0] and \"@\" not in elt[0] :\n",
    "            chrom = re.sub(\"chr\", \"\", elt[0])\n",
    "            pos=int(elt[1])\n",
    "            if chrom in dictionary and pos in dictionary[chrom] :\n",
    "                otp.writerow(elt)\n",
    "            else :\n",
    "                otp_2.writerow(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_db_me_other(info_file,threshold,delimiters):\n",
    "    seen_validate=set()\n",
    "    dic=defaultdict(list)\n",
    "    seen=[]\n",
    "    #next(info_file)\n",
    "    ME=csv.reader(open(info_file,\"r\"),delimiter=delimiters)\n",
    "    count=0\n",
    "    liste_found=[]\n",
    "    dic_last=defaultdict(float)\n",
    "    for elt in ME :\n",
    "        if \"#\" not in elt[0] :\n",
    "            clean_list = [x for x in elt if x != '']\n",
    "            parser=clean_list[2].split(\"_\")\n",
    "            if len(parser)<=4 :\n",
    "                #print(clean_list)\n",
    "                size_aligned =check_size_align(int(clean_list[12]),int(clean_list[11]))+1\n",
    "                parser=clean_list[2].split(\"_\")\n",
    "                chromosome=re.sub(\"chr\", \"\",parser[0])\n",
    "                position=int(parser[1])\n",
    "                size=int(parser[2])\n",
    "                #print(clean_list)\n",
    "                #print(size_aligned,size)\n",
    "                percentage=float(size_aligned)/float(size)\n",
    "                #print(size,size_aligned,percentage)\n",
    "                #print(clean_list)\n",
    "                head=chromosome+\"_\"+str(position)+\"_\"+str(size)\n",
    "                if percentage >=threshold :\n",
    "                    dic[head].append(percentage)\n",
    "\n",
    "    for elt in dic :\n",
    "        #print(dic[elt],elt)\n",
    "        best=max(dic[elt])\n",
    "        if best >=threshold :\n",
    "            dic_last[elt]=best\n",
    "            seen_validate.add(elt)\n",
    "            count+=1\n",
    "            #print(dic[elt],elt,best)\n",
    "    print(count)\n",
    "    return(dic_last)\n",
    "def make_db_me(info_file,threshold,delimiters):\n",
    "    seen_validate=set()\n",
    "    dic=defaultdict(list)\n",
    "    seen=[]\n",
    "    #next(info_file)\n",
    "    ME=csv.reader(open(info_file,\"r\"),delimiter=delimiters)\n",
    "    count=0\n",
    "    liste_found=[]\n",
    "    dic_last=defaultdict(float)\n",
    "    for elt in ME :\n",
    "        if \"#\" not in elt[0] :\n",
    "            clean_list = [x for x in elt if x != '']\n",
    "            parser=clean_list[2].split(\"_\")\n",
    "            if len(parser)<=4 :\n",
    "                #print(clean_list)\n",
    "                size_aligned =check_size_align(int(clean_list[12]),int(clean_list[11]))+1\n",
    "                parser=clean_list[2].split(\"_\")\n",
    "                chromosome=re.sub(\"chr\", \"\",parser[0])\n",
    "                position=int(parser[-2])\n",
    "                size=int(parser[-1])\n",
    "                #print(clean_list)\n",
    "                #print(size_aligned,size)\n",
    "                percentage=float(size_aligned)/float(size)\n",
    "                #print(size,size_aligned,percentage)\n",
    "                #print(clean_list)\n",
    "                head=chromosome+\"_\"+str(position)+\"_\"+str(size)\n",
    "                if percentage >=threshold :\n",
    "                    dic[head].append(percentage)\n",
    "\n",
    "    for elt in dic :\n",
    "        #print(dic[elt],elt)\n",
    "        best=max(dic[elt])\n",
    "        if best >=threshold :\n",
    "            dic_last[elt]=best\n",
    "            seen_validate.add(elt)\n",
    "            count+=1\n",
    "            #print(dic[elt],elt,best)\n",
    "    print(count)\n",
    "    return(dic_last)\n",
    "def count_same(liste_t,liste_q):\n",
    "    count=0\n",
    "    liste_unfound=[]\n",
    "    for elt in liste_q :\n",
    "        if elt in liste_t :\n",
    "            count+=1\n",
    "        else :\n",
    "            liste_unfound.append(elt)\n",
    "    if len(liste_unfound)==0 or len(liste_q)==0 :\n",
    "        FP=0\n",
    "    else :\n",
    "        FP=len(liste_unfound)/len(liste_q)\n",
    "    print(\"found \",count,\",percentage :\",count/len(liste_t),\",FP :\",FP,\",len ref\",len(liste_t),\",len query\",len(liste_q))\n",
    "    #return(liste_unfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header(el) :\n",
    "    splt=el.split(\"_\")\n",
    "    if len(splt)==4:\n",
    "        #print(element)\n",
    "        header=re.sub(\"chr\", \"\",splt[0])+\"_\"+splt[2]+\"_\"+splt[3]\n",
    "        #print(header)\n",
    "    else :\n",
    "        header=re.sub(\"chr\", \"\",splt[0])+\"_\"+splt[1]+\"_\"+splt[2]\n",
    "    return header\n",
    "def increment_dic(dic,liste,type_sv) :\n",
    "    count=0\n",
    "    if len(liste)==0 :\n",
    "        return dic\n",
    "    for element in liste :\n",
    "        header=get_header(element)\n",
    "        if header not in dic :\n",
    "            #print(\"ERROR\",header)\n",
    "            continue\n",
    "        if header in dic and type_sv not in dic[header]:\n",
    "            dic[header].add(type_sv)\n",
    "            count+=1\n",
    "            #print(header,type_sv,dic[header])\n",
    "        #if type_sv in dic[header] :\n",
    "            #print (header, dic[header], element)\n",
    "    print(type_sv,count)\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(inser):\n",
    "    allowed = \"ATCGatcg\"\n",
    "    if all(c in allowed for c in inser):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def get_dic_all(inpt) :\n",
    "    dic_all=[]\n",
    "    inpt_seq=csv.reader(open(inpt,\"r\"), delimiter=\"\\t\")\n",
    "    for element in inpt_seq :\n",
    "        if \"#\" not in element[0] and \"@\" not in element[0] :\n",
    "            parser = element[7].split(';')\n",
    "            svseq=parser[6].split(\"=\")[1].upper()\n",
    "            chrom = re.sub(\"chr\", \"\", element[0])\n",
    "            position=int(element[1])\n",
    "            headers=chrom+\"_\"+str(position)+\"_\"+str(len(svseq))\n",
    "            if headers not in dic_all and is_valid(svseq) and len(svseq)>=50 :\n",
    "                dic_all.append(headers)\n",
    "    return dic_all\n",
    "\n",
    "def get_dic_all_2(inpt) :\n",
    "    dic_all={}\n",
    "    inpt_seq=csv.reader(open(inpt,\"r\"), delimiter=\"\\t\")\n",
    "    for elt in inpt_seq :\n",
    "        if \"#\" not in elt[0] and len(elt[4])>len(elt[3]) and is_valid(elt[4]) :\n",
    "            headers=re.sub(\"chr\", \"\",elt[0])+\"_\"+elt[1] +\"_\"+str(len(elt[4]))\n",
    "            if headers not in dic_all :\n",
    "                dic_all[headers]={\"all\"}\n",
    "    return dic_all\n",
    "\n",
    "def count_novo(dic_all) :\n",
    "    count_unique=0\n",
    "    tot_dup=0\n",
    "    tot_trf=0\n",
    "    tot_tdup=0\n",
    "    tot_me=0\n",
    "    tot_cplx=0\n",
    "    reverse_dic={}\n",
    "    for elt in dic_all :\n",
    "        if tuple(dic_all[elt]) not  in reverse_dic :\n",
    "            reverse_dic[tuple(dic_all[elt])]=1\n",
    "        else :\n",
    "            reverse_dic[tuple(dic_all[elt])]+=1\n",
    "        if len(dic_all[elt])==1  and \"all\" in dic_all[elt]:\n",
    "            #print(dic_all[elt], elt)\n",
    "            count_unique+=1\n",
    "            continue\n",
    "        elif \"ME\" in dic_all[elt] :\n",
    "            tot_me+=1\n",
    "            continue\n",
    "        elif \"TRF\" in dic_all[elt] :\n",
    "            tot_trf+=1\n",
    "            continue\n",
    "        elif \"TD\" in dic_all[elt] :\n",
    "            tot_tdup+=1\n",
    "            continue\n",
    "        elif \"DUP\" in dic_all[elt] :\n",
    "            tot_dup+=1\n",
    "            continue\n",
    "        else :\n",
    "            tot_cplx+=1\n",
    "    print(\"new : \",count_unique, \" cplx : \", tot_cplx, \" remove : TD :\", tot_tdup, \" TRF : \",tot_trf, \" DUP : \",tot_dup, \" ME : \",tot_me)\n",
    "    return (reverse_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalized_size (dic,incr):\n",
    "    for element in dic :\n",
    "        if len(dic[element])<incr :\n",
    "            dic[element].append(0)\n",
    "    return dic\n",
    "\n",
    "def get_perfec_dic(incr,dic_alone,dic_merge) :\n",
    "    for elt in dic_alone :\n",
    "        if len(elt)>2:\n",
    "            if elt in dic_merge :\n",
    "                dic_merge[elt].append(int(dic_alone[elt]))\n",
    "            else :\n",
    "                if incr==1:\n",
    "                    dic_merge[elt]=[int(dic_alone[elt])]\n",
    "                else :\n",
    "                    dic_merge[elt]=[int(dic_alone[elt])]\n",
    "                while len(dic_merge[elt])<incr :\n",
    "                    dic_merge[elt].append(0)\n",
    "                \n",
    "    dic_merge=normalized_size(dic_merge,incr)\n",
    "    return dic_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(td,tr,me,dup,segm) :\n",
    "    liste_tot=[td,tr,me,dup,segm]\n",
    "    liste_tot.sort(key = lambda x: x[1],reverse=True)\n",
    "    #print(liste_tot)\n",
    "    return liste_tot[0]\n",
    "def count_v2(dic_all,dic_td,dic_tr,dic_me,dic_dup,threshold):\n",
    "    count_novo=0\n",
    "    count_me=0\n",
    "    count_tr=0\n",
    "    count_td=0\n",
    "    count_dup=0\n",
    "    count_order_me=0\n",
    "    count_order_tr=0\n",
    "    count_order_td=0\n",
    "    count_order_dup=0\n",
    "    liste_novo=[]\n",
    "    liste_td=[]\n",
    "    liste_me=[]\n",
    "    liste_tr=[]\n",
    "    liste_dup=[]\n",
    "    liste_td_o=[]\n",
    "    liste_me_o=[]\n",
    "    liste_tr_o=[]\n",
    "    liste_dup_o=[]\n",
    "    for elt in dic_all :\n",
    "        #print(elt,dic_all[elt])\n",
    "        #print(dic_td,dic_td[elt],dic_tr,dic_tr[elt],dic_me,dic_me[elt],dic_dup,dic_dup[elt])\n",
    "        liste_to_compare=[]\n",
    "        best_td=[\"TD\",0]\n",
    "        best_tr=[\"TR\",0]\n",
    "        best_me=[\"ME\",0]\n",
    "        best_dup=[\"DUP\",0]\n",
    "        if elt in dic_td :\n",
    "            best_td=[\"TD\",dic_td[elt]]\n",
    "        if elt in dic_tr :\n",
    "            best_tr=[\"TR\",dic_tr[elt]]\n",
    "        if elt in dic_me :\n",
    "            best_me=[\"ME\",dic_me[elt]]\n",
    "        if elt in dic_dup :\n",
    "            best_dup=[\"DUP\",dic_dup[elt]]\n",
    "        if elt not in dic_td and elt not in dic_tr and elt not in dic_me and elt not in dic_dup :\n",
    "            #print(elt)\n",
    "            count_novo+=1\n",
    "            liste_novo.append(dic_all[elt])\n",
    "            continue\n",
    "        #if threshold!=1 :\n",
    "        #    if best_td[1]<1-threshold and best_tr[1]<1-threshold and best_me[1]<1-threshold and best_dup[1]<1-threshold :\n",
    "        #        count_novo+=1\n",
    "        best=compare(best_td,best_tr,best_me,best_dup)\n",
    "        if threshold !=0 :\n",
    "            if best[1]>=threshold :\n",
    "                if best[0]==\"TD\"  :\n",
    "                    count_td+=1\n",
    "                    liste_td.append(dic_all[elt])\n",
    "                elif best[0]==\"TR\" :\n",
    "                    count_tr+=1\n",
    "                    liste_tr.append(dic_all[elt])\n",
    "                elif best[0]==\"ME\"  :\n",
    "                    count_me+=1\n",
    "                    liste_me.append(dic_all[elt])\n",
    "                elif best[0]==\"DUP\"  :\n",
    "                    count_dup+=1\n",
    "                    liste_dup.append(dic_all[elt])\n",
    "        else :\n",
    "            if best[0]==\"TD\"  :\n",
    "                count_td+=1\n",
    "                liste_td.append(dic_all[elt])\n",
    "            elif best[0]==\"TR\" :\n",
    "                count_tr+=1\n",
    "                liste_tr.append(dic_all[elt])\n",
    "            elif best[0]==\"ME\"  :\n",
    "                count_me+=1\n",
    "                liste_me.append(dic_all[elt])\n",
    "            elif best[0]==\"DUP\"  :\n",
    "                count_dup+=1\n",
    "                liste_dup.append(dic_all[elt])\n",
    "\n",
    "        if elt in dic_me :\n",
    "            count_order_me+=1\n",
    "            liste_me_o.append(dic_all[elt])\n",
    "            continue\n",
    "        if elt in dic_tr :\n",
    "            count_order_tr+=1\n",
    "            liste_tr_o.append(dic_all[elt])\n",
    "            continue\n",
    "        if elt in dic_td :\n",
    "            count_order_td+=1\n",
    "            liste_td_o.append(dic_all[elt])\n",
    "            continue\n",
    "        if elt in dic_dup :\n",
    "            count_order_dup+=1\n",
    "            liste_dup_o.append(dic_all[elt])\n",
    "            continue\n",
    "        #break\n",
    "    print (\"BEST align \",\"novo : \", count_novo, \"TD : \", count_td, \"TR : \", count_tr, \"ME : \", count_me, \"DUP : \", count_dup)\n",
    "    total=count_novo+count_td+count_tr+count_me+count_dup\n",
    "    total_order=count_novo+count_order_td+count_order_tr+count_order_me+count_order_dup\n",
    "    print (\"Order \",\"novo : \", count_novo, \"TD : \", count_order_td, \"TR : \", count_order_tr, \"ME : \", count_order_me, \"DUP : \", count_order_dup)\n",
    "    print(\"TOTAL :\", total, \" TOTAL order : \",total_order)\n",
    "    #return liste_td,liste_me,liste_tr,liste_dup,liste_novo,liste_td_o,liste_me_o,liste_tr_o,liste_dup_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(dic_all,dic_td,dic_tr,dic_me,dic_dup,segm_dup,not_valid,threshold,compo):\n",
    "    count_novo=0\n",
    "    count_novo_2=0\n",
    "    count_me=0\n",
    "    count_tr=0\n",
    "    count_td=0\n",
    "    count_dup=0\n",
    "    count_segm=0\n",
    "    count_order_me=0\n",
    "    count_order_tr=0\n",
    "    count_order_td=0\n",
    "    count_order_dup=0\n",
    "    count_order_segm=0\n",
    "    liste_novo=[]\n",
    "    liste_td=[]\n",
    "    liste_me=[]\n",
    "    liste_tr=[]\n",
    "    liste_dup=[]\n",
    "    liste_segm=[]\n",
    "    liste_td_o=[]\n",
    "    liste_me_o=[]\n",
    "    liste_tr_o=[]\n",
    "    liste_dup_o=[]\n",
    "    liste_segm_o=[]\n",
    "    print(len(segm_dup))\n",
    "    for elt in dic_all :\n",
    "        if elt not in dic_td and elt not in segm_dup and elt not in dic_tr and elt not in dic_me and elt not in dic_dup and elt not in segm_dup and elt not in not_valid :\n",
    "            #print(elt)\n",
    "            count_novo+=1\n",
    "            liste_novo.append(elt)\n",
    "            #if elt not in compo :\n",
    "            #    count_novo+=1\n",
    "            #    liste_novo.append(elt)\n",
    "            #elif compo[elt]/int(elt.split(\"_\")[-1])<threshold :\n",
    "            #    count_novo_2+=1\n",
    "            #    liste_novo.append(elt)\n",
    "            #else :\n",
    "            #    print(elt,compo[elt])\n",
    "        #if threshold!=1 :\n",
    "        #    if best_td[1]<1-threshold and best_tr[1]<1-threshold and best_me[1]<1-threshold and best_dup[1]<1-threshold :\n",
    "        #        count_novo+=1\n",
    "        if elt in dic_me :\n",
    "            count_order_me+=1\n",
    "            liste_me_o.append(elt)\n",
    "            continue\n",
    "        if elt in dic_tr :\n",
    "            count_order_tr+=1\n",
    "            liste_tr_o.append(elt)\n",
    "            continue\n",
    "        if elt in segm_dup :\n",
    "            count_order_segm+=1\n",
    "            liste_segm_o.append(elt)\n",
    "            continue\n",
    "        if elt in dic_td :\n",
    "            count_order_td+=1\n",
    "            liste_td_o.append(elt)\n",
    "            continue\n",
    "        if elt in dic_dup :\n",
    "            count_order_dup+=1\n",
    "            liste_dup_o.append(elt)\n",
    "            continue\n",
    "        #break\n",
    "    total_order=count_novo+count_order_td+count_order_tr+count_order_me+count_order_dup\n",
    "    print (\"Order \",\"novo : \", count_novo, \"TD : \", count_order_td, \"TR : \", count_order_tr, \"ME : \", count_order_me, \"DUP : \", count_order_dup)#, \"SEGM : \",count_order_segm)\n",
    "    #print(\" TOTAL order : \",total_order)\n",
    "    return liste_td,liste_me,liste_tr,liste_dup,liste_novo,liste_td_o,liste_me_o,liste_tr_o,liste_dup_o,liste_segm_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complex(dic,td,tr,me,dup,novo,segm):\n",
    "    count=0\n",
    "    liste_complex=[]\n",
    "    for head in dic :\n",
    "        if head not in novo and head not in td and head not in me and head not in tr and head not in dup and head not in segm:\n",
    "            count+=1\n",
    "            liste_complex.append(head)\n",
    "    print(count)\n",
    "    return liste_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_occu(liste,threshold):\n",
    "    count=0\n",
    "    for i in liste :\n",
    "        if i>= threshold :\n",
    "            count+=1\n",
    "    return count\n",
    "liste_chais=[]\n",
    "inpt=csv.reader(open(\"/home/wesley/genouest/Blast/Chaisson/ME/Mobile_Elt_Chaisson_HG38.vcf\"),delimiter=\"\\t\")\n",
    "for element in inpt :\n",
    "    parser = element[7].split(';')\n",
    "    svseq=parser[6].split(\"=\")[1].upper()\n",
    "    chrom = re.sub(\"chr\", \"\", element[0])\n",
    "    position=int(element[1])\n",
    "    headers=chrom+\"_\"+str(position)+\"_\"+str(len(svseq))\n",
    "    liste_chais.append(headers)\n",
    "def get_list_occu(info_file,threshold,dic_all): \n",
    "    inpt=csv.reader(open(info_file,\"r\"),delimiter=\"\\t\")\n",
    "    count=0\n",
    "    liste_all=defaultdict()\n",
    "    dic=defaultdict(list)\n",
    "\n",
    "    count_td=0\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    for elt in inpt :\n",
    "        if len(elt[9].split(\"_\"))<=4 :\n",
    "            match=int(elt[0])\n",
    "            size_align=check_size_align(int(elt[12]),int(elt[11]))\n",
    "            size_align_ref=check_size_align(int(elt[16]),int(elt[15]))\n",
    "            size_inser=int(elt[9].split(\"_\")[-1])\n",
    "            chrom_inser=re.sub(\"chr\", \"\",elt[9].split(\"_\")[0])\n",
    "            inser_pos=int(elt[9].split(\"_\")[2])\n",
    "            chrom_ref=re.sub(\"chr\", \"\",elt[13])\n",
    "            ref_pos=int(elt[15])\n",
    "            heads=chrom_inser+\"_\"+str(inser_pos)+\"_\"+str(size_inser)\n",
    "            #print(size_align,size_inser,chrom_inser,inser_pos,chrom_ref,ref_pos)\n",
    "            percentage=float(size_align/size_inser)\n",
    "            percentage_match=float(match/size_inser)\n",
    "            dic[heads].append(percentage)\n",
    "    for head in dic :\n",
    "        if head in dic_all :\n",
    "            counts=get_occu(dic[head],threshold)\n",
    "            liste_all[head]=counts\n",
    "        else :\n",
    "            liste_all[head]=0\n",
    "    return liste_all\n",
    "def get_list_occu_2(info_file,threshold,dic_all): \n",
    "    inpt=csv.reader(open(info_file,\"r\"),delimiter=\"\\t\")\n",
    "    count=0\n",
    "    liste_all=defaultdict()\n",
    "    dic=defaultdict(list)\n",
    "\n",
    "    count_td=0\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    for elt in inpt :\n",
    "        match=int(elt[0])\n",
    "        size_align=check_size_align(int(elt[12]),int(elt[11]))\n",
    "        size_align_ref=check_size_align(int(elt[16]),int(elt[15]))\n",
    "        size_inser=int(elt[9].split(\"_\")[-1])\n",
    "        chrom_inser=re.sub(\"chr\", \"\",elt[9].split(\"_\")[0])\n",
    "        inser_pos=int(elt[9].split(\"_\")[1])\n",
    "        chrom_ref=re.sub(\"chr\", \"\",elt[13])\n",
    "        ref_pos=int(elt[15])\n",
    "        heads=chrom_inser+\"_\"+str(inser_pos)+\"_\"+str(size_inser)\n",
    "        #print(size_align,size_inser,chrom_inser,inser_pos,chrom_ref,ref_pos)\n",
    "        percentage=float(size_align/size_inser)\n",
    "        percentage_match=float(match/size_inser)\n",
    "        dic[heads].append(percentage)\n",
    "    for head in dic :\n",
    "        if head in dic_all :\n",
    "            counts=get_occu(dic[head],threshold)\n",
    "            liste_all[head]=counts\n",
    "        else :\n",
    "            liste_all[head]=0\n",
    "    return liste_all\n",
    "def get_list_percentage(info_file,threshold,td,me,tr,dup,novo,td_o,me_o,tr_o,dup_o,complexe,segm,dic_all): \n",
    "    inpt=csv.reader(open(info_file,\"r\"),delimiter=\"\\t\")\n",
    "    count=0\n",
    "    seen_validate=set()\n",
    "    dic=defaultdict(list)\n",
    "    dic_last=defaultdict(float)\n",
    "    black_list=[]\n",
    "    dic_td=defaultdict(float)\n",
    "    count_td=0\n",
    "    liste_occurence_me=[]\n",
    "    liste_occurence_tr=[]\n",
    "    liste_occurence_td=[]\n",
    "    liste_occurence_dp=[]\n",
    "    liste_occurence_novo=[]\n",
    "    liste_occurence_me_o=[]\n",
    "    liste_occurence_tr_o=[]\n",
    "    liste_occurence_td_o=[]\n",
    "    liste_occurence_dp_o=[]\n",
    "    liste_count_size=[]\n",
    "    liste_low_size=[]\n",
    "    liste_occurrence_complex=[]\n",
    "    liste_unassigned=[]\n",
    "    liste_all=defaultdict()\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    for elt in inpt :\n",
    "        match=int(elt[0])\n",
    "        size_align=check_size_align(int(elt[12]),int(elt[11]))\n",
    "        size_align_ref=check_size_align(int(elt[16]),int(elt[15]))\n",
    "        size_inser=int(elt[9].split(\"_\")[3])\n",
    "        chrom_inser=re.sub(\"chr\", \"\",elt[9].split(\"_\")[0])\n",
    "        inser_pos=int(elt[9].split(\"_\")[2])\n",
    "        chrom_ref=re.sub(\"chr\", \"\",elt[13])\n",
    "        ref_pos=int(elt[15])\n",
    "        heads=chrom_inser+\"_\"+str(inser_pos)+\"_\"+str(size_inser)\n",
    "        #print(size_align,size_inser,chrom_inser,inser_pos,chrom_ref,ref_pos)\n",
    "        percentage=float(size_align/size_inser)\n",
    "        percentage_match=float(match/size_inser)\n",
    "        dic[heads].append(percentage)\n",
    "    for he in novo :\n",
    "        if he not in dic :\n",
    "            liste_occurence_novo.append(0)\n",
    "            liste_low_size.append(0)\n",
    "    for head in dic :\n",
    "        if head in dic_all :\n",
    "            counts=get_occu(dic[head],threshold)\n",
    "            if counts >= 600 :\n",
    "                liste_count_size.append(counts)\n",
    "            if counts < 600 :\n",
    "                liste_low_size.append(counts)\n",
    "            if head in td :\n",
    "                liste_occurence_td.append(counts)\n",
    "            if head in me :\n",
    "                liste_occurence_me.append(counts)\n",
    "            if head in tr :\n",
    "                liste_occurence_tr.append(counts)\n",
    "            if head in dup :\n",
    "                liste_occurence_dp.append(counts)\n",
    "            if head in novo :\n",
    "                liste_occurence_novo.append(counts)\n",
    "            if head in td_o :\n",
    "                liste_occurence_td_o.append(counts)\n",
    "            if head in me_o :\n",
    "                liste_occurence_me_o.append(counts)\n",
    "            if head in tr_o :\n",
    "                liste_occurence_tr_o.append(counts)\n",
    "            if head in dup_o :\n",
    "                liste_occurence_dp_o.append(counts)\n",
    "            if head in complexe :\n",
    "                liste_occurrence_complex.append(counts)\n",
    "            if head in segm :\n",
    "                liste_unassigned.append(counts)\n",
    "            liste_all[head]=counts\n",
    "    return liste_occurence_novo,liste_occurence_td_o,liste_occurence_me_o,liste_occurence_tr_o,liste_occurence_dp_o,liste_occurrence_complex,liste_unassigned,liste_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_percentage_size(info_file,threshold,td,me,tr,dup,novo,td_o,me_o,tr_o,dup_o,complexe,dic_lim): \n",
    "    inpt=csv.reader(open(info_file,\"r\"),delimiter=\"\\t\")\n",
    "    count=0\n",
    "    seen_validate=set()\n",
    "    dic=defaultdict(list)\n",
    "    dic_last=defaultdict(float)\n",
    "    black_list=[]\n",
    "    dic_td=defaultdict(float)\n",
    "    count_td=0\n",
    "    liste_occurence_me=[]\n",
    "    liste_occurence_tr=[]\n",
    "    liste_occurence_td=[]\n",
    "    liste_occurence_dp=[]\n",
    "    liste_occurence_novo=[]\n",
    "    liste_occurence_me_o=[]\n",
    "    liste_occurence_tr_o=[]\n",
    "    liste_occurence_td_o=[]\n",
    "    liste_occurence_dp_o=[]\n",
    "    liste_occurence_novo_o=[]\n",
    "    liste_count_size=[]\n",
    "    liste_low_size=[]\n",
    "    low_chaiss=[]\n",
    "    high_chaiss=[]\n",
    "    liste_occurence_complexe_low=[]\n",
    "    liste_occurence_complexe_high=[]\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    for elt in inpt :\n",
    "        match=int(elt[0])\n",
    "        size_align=check_size_align(int(elt[12]),int(elt[11]))\n",
    "        size_align_ref=check_size_align(int(elt[16]),int(elt[15]))\n",
    "        size_inser=int(elt[9].split(\"_\")[3])\n",
    "        chrom_inser=re.sub(\"chr\", \"\",elt[9].split(\"_\")[0])\n",
    "        inser_pos=int(elt[9].split(\"_\")[2])\n",
    "        chrom_ref=re.sub(\"chr\", \"\",elt[13])\n",
    "        ref_pos=int(elt[15])\n",
    "        heads=chrom_inser+\"_\"+str(inser_pos)+\"_\"+str(size_inser)\n",
    "        #print(size_align,size_inser,chrom_inser,inser_pos,chrom_ref,ref_pos)\n",
    "        percentage=float(size_align/size_inser)\n",
    "        percentage_match=float(match/size_inser)\n",
    "        dic[heads].append(percentage)\n",
    "    for he in novo :\n",
    "        if he not in dic :\n",
    "            liste_occurence_novo_o.append(int(he.split(\"_\")[2]))\n",
    "    for head in dic :\n",
    "        counts=get_occu(dic[head],threshold)\n",
    "        if head in dic_lim :\n",
    "            if int(head.split(\"_\")[2])==0:\n",
    "                        print(head)\n",
    "            if counts >= 600 :\n",
    "                liste_count_size.append(int(head.split(\"_\")[2]))\n",
    "                #if head in chaisson_liste :\n",
    "                #    high_chaiss.append(int(head.split(\"_\")[2]))\n",
    "                if head in td_o :\n",
    "                    liste_occurence_td.append(int(head.split(\"_\")[2]))\n",
    "                if head in me_o :\n",
    "                    liste_occurence_me.append(int(head.split(\"_\")[2]))\n",
    "                if head in tr_o :\n",
    "                    liste_occurence_tr.append(int(head.split(\"_\")[2]))\n",
    "                if head in dup :\n",
    "                    #print(head)\n",
    "                    liste_occurence_dp.append(int(head.split(\"_\")[2]))\n",
    "                if head in novo :\n",
    "                    liste_occurence_novo.append(int(head.split(\"_\")[2]))\n",
    "                if head in complexe :\n",
    "                    liste_occurence_complexe_high.append(int(head.split(\"_\")[2]))\n",
    "            if counts < 600 :\n",
    "                liste_low_size.append(int(head.split(\"_\")[2]))\n",
    "                #if head in chaisson_liste :\n",
    "                #    low_chaiss.append(int(head.split(\"_\")[2]))\n",
    "                if head in novo :\n",
    "                    liste_occurence_novo_o.append(int(head.split(\"_\")[2]))\n",
    "                if head in td_o :\n",
    "                    liste_occurence_td_o.append(int(head.split(\"_\")[2]))\n",
    "                if head in me_o :\n",
    "                    liste_occurence_me_o.append(int(head.split(\"_\")[2]))\n",
    "                if head in tr_o :\n",
    "                    liste_occurence_tr_o.append(int(head.split(\"_\")[2]))\n",
    "                if head in dup_o :\n",
    "                    liste_occurence_dp_o.append(int(head.split(\"_\")[2]))\n",
    "                if head in complexe :\n",
    "                    liste_occurence_complexe_low.append(int(head.split(\"_\")[2]))\n",
    "    return liste_occurence_td,liste_occurence_me,liste_occurence_tr,liste_occurence_dp,liste_occurence_novo,liste_occurence_td_o,liste_occurence_me_o,liste_occurence_tr_o,liste_occurence_dp_o,liste_occurence_novo_o,liste_count_size,liste_low_size,low_chaiss,high_chaiss,liste_occurence_complexe_high,liste_occurence_complexe_low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_head(info_file,threshold,td,me,tr,dup,novo,td_o,me_o,tr_o,dup_o,complexe,dic_lim): \n",
    "    inpt=csv.reader(open(info_file,\"r\"),delimiter=\"\\t\")\n",
    "    count=0\n",
    "    seen_validate=set()\n",
    "    dic=defaultdict(list)\n",
    "    dic_last=defaultdict(float)\n",
    "    black_list=[]\n",
    "    dic_td=defaultdict(float)\n",
    "    count_td=0\n",
    "    liste_occurence_me=[]\n",
    "    liste_occurence_tr=[]\n",
    "    liste_occurence_td=[]\n",
    "    liste_occurence_dp=[]\n",
    "    liste_occurence_novo=[]\n",
    "    liste_occurence_me_o=[]\n",
    "    liste_occurence_tr_o=[]\n",
    "    liste_occurence_td_o=[]\n",
    "    liste_occurence_dp_o=[]\n",
    "    liste_count_size=[]\n",
    "    liste_low_size=[]\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    next(inpt)\n",
    "    for elt in inpt :\n",
    "        match=int(elt[0])\n",
    "        size_align=check_size_align(int(elt[12]),int(elt[11]))\n",
    "        size_align_ref=check_size_align(int(elt[16]),int(elt[15]))\n",
    "        size_inser=int(elt[9].split(\"_\")[3])\n",
    "        chrom_inser=re.sub(\"chr\", \"\",elt[9].split(\"_\")[0])\n",
    "        inser_pos=int(elt[9].split(\"_\")[2])\n",
    "        chrom_ref=re.sub(\"chr\", \"\",elt[13])\n",
    "        ref_pos=int(elt[15])\n",
    "        heads=chrom_inser+\"_\"+str(inser_pos)+\"_\"+str(size_inser)\n",
    "        #print(size_align,size_inser,chrom_inser,inser_pos,chrom_ref,ref_pos)\n",
    "        percentage=float(size_align/size_inser)\n",
    "        percentage_match=float(match/size_inser)\n",
    "        dic[heads].append(percentage)\n",
    "    for he in novo :\n",
    "        if he in dic_lim :\n",
    "            if he not in dic :\n",
    "                liste_low_size.append(he)\n",
    "    for head in dic :\n",
    "        if head in dic_lim :\n",
    "            counts=get_occu(dic[head],threshold)\n",
    "            if counts >= 600 :\n",
    "                liste_count_size.append(head)\n",
    "            if counts < 600 :\n",
    "                liste_low_size.append(head)\n",
    "       \n",
    "    return liste_count_size,liste_low_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_plus_minus(start,end):\n",
    "    if start<=end :\n",
    "        return start,end\n",
    "    else :\n",
    "        return end,start\n",
    "def check_strand(a,b):\n",
    "    if int(b)<int(a) :\n",
    "        return (a-b)+1\n",
    "    else :\n",
    "        return (b-a)+1\n",
    "def check_validity(ide,pos,size_ins):\n",
    "    if ide ==\"start\" and pos>=size_ins-10 :\n",
    "        return True\n",
    "    if ide ==\"end\" and pos<=10 :\n",
    "        return True\n",
    "\n",
    "def check_homology(couple) :\n",
    "    homo_start=False\n",
    "    homo_end=False\n",
    "    if couple[0] ==\"start\" :\n",
    "        valid_query=check_validity(couple[0],couple[3],couple[-1])\n",
    "        if valid_query :\n",
    "            homo_start=check_validity(\"end\",couple[5],couple[-1])\n",
    "            homo_end=check_validity(\"start\",couple[6],couple[-1])\n",
    "    if couple[0] ==\"end\" :\n",
    "        valid_query=check_validity(couple[0],couple[2],couple[-1])\n",
    "        if valid_query :\n",
    "            homo_start=check_validity(\"end\",couple[5],couple[-1])\n",
    "            homo_end=check_validity(\"start\",couple[6],couple[-1])\n",
    "            \n",
    "    if homo_start and homo_end :\n",
    "        return 1,1\n",
    "    if homo_start and not homo_end :\n",
    "        return 1,0\n",
    "    if not homo_start and homo_end :\n",
    "        return 0,1\n",
    "    else :\n",
    "        return 0,0\n",
    "def get_couple(elt):\n",
    "    ref_identifiant=elt[0].split(\"_\")[-1]\n",
    "    ref_size_insertion=int(elt[1].split(\"_\")[-1])\n",
    "    ref_qs=int(elt[6])\n",
    "    ref_qe=int(elt[7])\n",
    "    ref_ss=int(elt[8])\n",
    "    ref_se=int(elt[9])\n",
    "    ref_size_align_query=int(check_strand(ref_qs,ref_qe))\n",
    "    ref_size_align_s=int(check_strand(ref_ss,ref_se))\n",
    "    ref_couple=[ref_identifiant,int(elt[3]),ref_qs,ref_qe,ref_size_align_s,ref_ss,ref_se,ref_size_insertion]\n",
    "    return ref_couple \n",
    "\n",
    "def get_info(elt):\n",
    "    ref_couple=[]\n",
    "    ref=elt[0]\n",
    "    key=re.sub(\"chr\", \"\",elt[1].split(\"_\")[0])+\"_\"+elt[1].split(\"_\")[1]+\"_\"+elt[1].split(\"_\")[-1]\n",
    "    ref_couple=get_couple(elt)\n",
    "    homo_start,homo_end=check_homology(ref_couple)\n",
    "    ref_couple.append(homo_start)\n",
    "    ref_couple.append(homo_end)\n",
    "    return ref,key,ref_couple\n",
    "def get_all(inpt) :\n",
    "    dic=defaultdict(list)\n",
    "    inpts=csv.reader(open(inpt,\"r\"), delimiter='\\t')\n",
    "    ref=\"\"\n",
    "    ref_couple_end=[]\n",
    "    ref_couple_start=[]\n",
    "    for elt in inpts :\n",
    "        if int(elt[8])< int(elt[9]) and int(elt[6])<int(elt[7]) :\n",
    "            if int(elt[8])<=10 :\n",
    "                if ref ==\"\" or not ref_couple_start :\n",
    "                    ref,key,ref_couple_start=get_info(elt)\n",
    "                    continue\n",
    "                elif elt[0] ==ref  :\n",
    "                    couple=get_couple(elt)\n",
    "                    homo_start,homo_end=check_homology(couple)\n",
    "                    couple.append(homo_start)\n",
    "                    couple.append(homo_end)\n",
    "                    #print(homo_start,elt[8],ref_couple[5],homo_end,elt[9],ref_couple[6])\n",
    "                    if (homo_start and int(elt[8])<ref_couple_start[5]):\n",
    "                        ref_couple_start=couple\n",
    "                    elif (homo_start and int(elt[8])==ref_couple_start[5] and int(couple[1])>int(ref_couple_start[1])):\n",
    "                        ref_couple_start=couple\n",
    "                   # else : \n",
    "                    #    print(\"START\",ref_couple_start,couple)\n",
    "                elif elt[0]!=ref and ref_couple_start :\n",
    "                    #print(elt,ref_couple)\n",
    "                    if ref_couple_start[8] or ref_couple_start[9] :\n",
    "                        dic[key].append(ref_couple_start)\n",
    "                        #break\n",
    "                    ref,key,ref_couple_start=get_info(elt)\n",
    "                    continue\n",
    "\n",
    "            elif int(elt[9])>=int(elt[1].split(\"_\")[-1])-10 :\n",
    "                #print(elt)\n",
    "                if ref ==\"\" or not ref_couple_end:\n",
    "                    ref,key,ref_couple_end=get_info(elt)\n",
    "                    continue\n",
    "                elif elt[0] ==ref  :\n",
    "                    couple=get_couple(elt)\n",
    "                    homo_start,homo_end=check_homology(couple)\n",
    "                    couple.append(homo_start)\n",
    "                    couple.append(homo_end)\n",
    "                 #   print(\"COUPLE\",couple,ref_couple_end)\n",
    "                    #print(homo_start,elt[8],ref_couple[5],homo_end,elt[9],ref_couple[6])\n",
    "                    if  (homo_end and int(elt[9])>ref_couple_end[6]):\n",
    "                        ref_couple_end=couple\n",
    "                    elif (homo_end and int(elt[9])==ref_couple_end[6]and int(couple[1])>int(ref_couple_end[1])):\n",
    "                        ref_couple_end=couple\n",
    "                  #  else :\n",
    "                   #      print(\"END\",ref_couple_end,couple)\n",
    "                elif elt[0]!=ref and ref_couple_end :\n",
    "                    #print(elt,ref_couple)\n",
    "                    if ref_couple_end[8] or ref_couple_end[9] :\n",
    "                        dic[key].append(ref_couple_end)\n",
    "                        #break\n",
    "                    ref,key,ref_couple_end=get_info(elt)\n",
    "                    continue\n",
    "            #else :\n",
    "                #print(\"PB\", elt)\n",
    "    dic[key].append(ref_couple_start)\n",
    "    dic[key].append(ref_couple_end)\n",
    "    #print(dic)s_2\n",
    "    return dic\n",
    "\n",
    "def tests (inpt,threshold) :\n",
    "    dic=get_all(inpt)\n",
    "    return dic\n",
    "\n",
    "\n",
    "def get_dic_tandem_homology(d,threshold,liste_tandem):\n",
    "    tandem_dic_start=defaultdict(list)\n",
    "    tandem_dic_end=defaultdict(list)\n",
    "    tandem_dic_both=defaultdict(list)\n",
    "    to_remove=[]\n",
    "    for elt in d :\n",
    "        if elt in liste_tandem :\n",
    "            size_inser=int(elt.split(\"_\")[-1])\n",
    "            tandem_start=False \n",
    "            tandem_end=False\n",
    "            for e in d[elt] :\n",
    "                #print(e)\n",
    "                if (e[0] ==\"start\" and e[-1]==1 and e[-2]==1) or int(e[4])/size_inser >=threshold :\n",
    "                    tandem_start=True\n",
    "                if (e[0] == \"end\" and e[-1]==1 and e[-2]==1) or int(e[4])/size_inser >=threshold :\n",
    "                    tandem_end=True\n",
    "            if tandem_start and not tandem_end :\n",
    "                tandem_dic_start[elt]=d[elt]\n",
    "            if not tandem_start and  tandem_end :\n",
    "                tandem_dic_end[elt]=d[elt]\n",
    "            if tandem_start and  tandem_end :\n",
    "                #print(elt)\n",
    "                tandem_dic_both[elt]=d[elt]\n",
    "\n",
    "            if tandem_start  or tandem_end :\n",
    "                to_remove.append(elt)\n",
    "    for i in to_remove :   \n",
    "        if i in d :\n",
    "            del d[i]\n",
    "    return d,tandem_dic_start,tandem_dic_end,tandem_dic_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-88c9ee537311>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-88c9ee537311>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    for i in range (len(dic[elt]))\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_all_2s(inpt,d,t) :\n",
    "    dic=defaultdict(list)\n",
    "    inpts=csv.reader(open(inpt,\"r\"), delimiter='\\t')\n",
    "    for elt in inpts :\n",
    "        #print(elt)\n",
    "        key=re.sub(\"chr\", \"\",elt[1].split(\"_\")[0])+\"_\"+elt[1].split(\"_\")[1]+\"_\"+elt[1].split(\"_\")[-1]\n",
    "        ide_perc=float(int(elt[3])-int(elt[4])-int(elt[5]))/int(elt[3])\n",
    "        if int(elt[9])>int(elt[8]) and int(elt[7])>int(elt[6]) and ide_perc>=t and (int(elt[9])>=int(elt[1].split(\"_\")[-1])-10 or int(elt[8])<=10) :\n",
    "            ref_couple=get_couple(elt)\n",
    "            homo_start,homo_end=check_homology(ref_couple)\n",
    "            \n",
    "            ref_couple.append(homo_start)\n",
    "            ref_couple.append(homo_end)\n",
    "            dic[key].append(ref_couple)\n",
    "    return dic\n",
    "def process_2 (dic) :\n",
    "    dic_final=defaultdict(list)\n",
    "    for elt in dic :\n",
    "        i=0\n",
    "        if len(dic[elt])==1 :\n",
    "            dic_final[elt]=dic[elt]\n",
    "        else :\n",
    "            for i in range (len(dic[elt])) :\n",
    "                if i==0 :\n",
    "                    ref =dic[elt][0]\n",
    "                else :\n",
    "                    if (dic[elt][i][-2] and int(dic[elt][i][1])>int(ref[1])) or (dic[elt][i][-1] and int(dic[elt][i][1])>int(ref[1])):\n",
    "                        ref=dic[elt][i]\n",
    "            dic_final[elt]=ref\n",
    "    return dic_final\n",
    "def tests_v2 (inpt,threshold,d,t) :\n",
    "    dic=get_all_2s(inpt,d,t)\n",
    "    dic_f=process_2(dic)\n",
    "    return dic_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_2(inpt,d,t) :\n",
    "    dic=defaultdict(list)\n",
    "    inpts=csv.reader(open(inpt,\"r\"), delimiter='\\t')\n",
    "    ref=\"\"\n",
    "    ref_couple=[]\n",
    "    couple=[]\n",
    "    for elt in inpts :\n",
    "        old_key=re.sub(\"chr\", \"\",elt[1].split(\"_\")[0])+\"_\"+elt[1].split(\"_\")[1]+\"_\"+elt[1].split(\"_\")[-1]\n",
    "        if old_key==\"3_88522029_341\" :\n",
    "            print(elt)\n",
    "        ide_perc=float(int(elt[3])-int(elt[4])-int(elt[5]))/int(elt[3])\n",
    "        #print(elt,ide_perc)\n",
    "        if int(elt[9])>int(elt[8]) and int(elt[7])>int(elt[6]) and ide_perc>=t : #and key in d :\n",
    "            if int(elt[9])>=int(elt[1].split(\"_\")[-1])-10 or int(elt[8])<=10 or int(elt[3])!=0 :\n",
    "                if ref ==\"\":\n",
    "                    ref=elt[0]\n",
    "                    key=re.sub(\"chr\", \"\",elt[1].split(\"_\")[0])+\"_\"+elt[1].split(\"_\")[1]+\"_\"+elt[1].split(\"_\")[-1]\n",
    "                    ref_couple=get_couple(elt)\n",
    "                    homo_start,homo_end=check_homology(ref_couple)\n",
    "                    ref_couple.append(homo_start)\n",
    "                    ref_couple.append(homo_end)\n",
    "                    if key==\"3_88522029_341\" :\n",
    "                        print(elt,ref_couple)\n",
    "                    continue            \n",
    "                elif elt[0] ==ref  :\n",
    "                    couple=get_couple(elt)\n",
    "                    homo_start,homo_end=check_homology(couple)\n",
    "                    couple.append(homo_start)\n",
    "                    couple.append(homo_end)\n",
    "                    \n",
    "                    #print(homo_start,elt[8],ref_couple[5],homo_end,elt[9],ref_couple[6])\n",
    "                    if (homo_start and int(couple[1])>int(ref_couple[1])) or (homo_end and int(couple[1])>int(ref_couple[1])):\n",
    "                        ref_couple=couple\n",
    "                elif elt[0]!=ref and ref_couple :\n",
    "                    #print(elt,\"COUPLE\",ref_couple)\n",
    "                    if ref_couple[8] or ref_couple[9] :\n",
    "                        dic[key].append(ref_couple)\n",
    "                        if key==\"3_88522029_341\" :\n",
    "                            print(ref_couple)\n",
    "                        #break\n",
    "                    ref=elt[0]\n",
    "                    key=re.sub(\"chr\", \"\",elt[1].split(\"_\")[0])+\"_\"+elt[1].split(\"_\")[1]+\"_\"+elt[1].split(\"_\")[-1]\n",
    "                    ref_couple=get_couple(elt)\n",
    "                    homo_start,homo_end=check_homology(ref_couple)\n",
    "                    ref_couple.append(homo_start)\n",
    "                    ref_couple.append(homo_end)\n",
    "                    continue\n",
    "            else :\n",
    "                print(elt)\n",
    "        else :\n",
    "            if elt[0]!=ref and ref_couple :\n",
    "                    #print(elt,\"COUPLE\",ref_couple)\n",
    "                    if ref_couple[8] or ref_couple[9] :\n",
    "                        dic[key].append(ref_couple)\n",
    "                        #break\n",
    "                    if key==\"3_88522029_341\" :\n",
    "                        print(ref_couple)\n",
    "                    ref=elt[0]\n",
    "                    old_key=re.sub(\"chr\", \"\",elt[1].split(\"_\")[0])+\"_\"+elt[1].split(\"_\")[1]+\"_\"+elt[1].split(\"_\")[-1]\n",
    "                    ref_couple=get_couple(elt)\n",
    "                    homo_start,homo_end=check_homology(ref_couple)\n",
    "                    ref_couple.append(homo_start)\n",
    "                    ref_couple.append(homo_end)\n",
    "                    continue\n",
    "    if ref_couple and (ref_couple[8] or ref_couple[9]) :\n",
    "                dic[key].append(ref_couple)\n",
    "    #print(dic)\n",
    "    return dic\n",
    "\n",
    "def tests_2 (inpt,threshold,d,t) :\n",
    "    dic=get_all_2(inpt,d,t)\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dic(dic,td,tr,me,novo,dp,cplx) :\n",
    "    dic_mh_me=defaultdict(list)\n",
    "    dic_mh_tr=defaultdict(list)\n",
    "    dic_mh_td=defaultdict(list)\n",
    "    dic_mh_dp=defaultdict(list)\n",
    "    dic_mh_novo=defaultdict(list)\n",
    "    dic_mh_cplx=defaultdict(list)\n",
    "    for elt in dic :\n",
    "        if elt in td :\n",
    "            dic_mh_td[elt]=dic[elt]\n",
    "        elif elt in tr :\n",
    "            dic_mh_tr[elt]=dic[elt]\n",
    "        elif elt in dp :\n",
    "            dic_mh_dp[elt]=dic[elt]\n",
    "        elif elt in me :\n",
    "            dic_mh_me[elt]=dic[elt]\n",
    "        elif elt in novo :\n",
    "            dic_mh_novo[elt]=dic[elt]\n",
    "        elif elt in cplx :\n",
    "            dic_mh_cplx[elt]=dic[elt]\n",
    "    #print(len(dic),len(dic_mh_me)+len(dic_mh_tr)+len(dic_mh_td)+len(dic_mh_dp)+len(dic_mh_novo)+len(dic_mh_cplx))\n",
    "    return dic_mh_me,dic_mh_tr,dic_mh_td,dic_mh_dp,dic_mh_novo,dic_mh_cplx\n",
    "def get_liste_mh(d):\n",
    "    liste_match_all_s=[]\n",
    "    liste_match_left_bs=[]\n",
    "    liste_match_right_bs=[]\n",
    "    for elt in d :\n",
    "        if len(d[elt])==1 :\n",
    "            couple=d[elt]\n",
    "            liste_match_all_s.append(int(couple[0][4]))\n",
    "\n",
    "        elif len(d[elt])==2 :\n",
    "            couple=d[elt]\n",
    "            liste_match_left_bs.append(int(couple[0][4]))\n",
    "            liste_match_right_bs.append(int(couple[1][4]))\n",
    "        else :\n",
    "            liste_match_all_s.append(0)\n",
    "    return liste_match_all_s,liste_match_left_bs,liste_match_right_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cross(d_all):\n",
    "    count_cross=0\n",
    "    count_not_cross=0\n",
    "    count_double_cross=0\n",
    "    count_double_not_cross=0\n",
    "    count_double_one_cross=0\n",
    "    liste_cross=[]\n",
    "    liste_not_cross=[]\n",
    "    liste_double_cross=[]\n",
    "    liste_double_not_cross=[]\n",
    "    liste_double_one_cross=[]\n",
    "    tot_not_cross=[]\n",
    "    for elt in d_all :\n",
    "        if len(d_all[elt])==1 :\n",
    "            #print(d[elt])\n",
    "            if d_all[elt][0][0] ==\"start\" :\n",
    "                if d_all[elt][0][9]==1 :\n",
    "                    count_cross+=1\n",
    "                    liste_cross.append(d_all[elt][0][1])\n",
    "                else :\n",
    "                    count_not_cross+=1\n",
    "                    #print(elt,d[elt])\n",
    "                    liste_not_cross.append(d_all[elt][0][1])\n",
    "            if d_all[elt][0][0] ==\"end\" :\n",
    "                if d_all[elt][0][8]==1 :\n",
    "                    count_cross+=1\n",
    "                    liste_cross.append(d_all[elt][0][1])\n",
    "                else :\n",
    "                    count_not_cross+=1 \n",
    "                    liste_not_cross.append(d_all[elt][0][1])\n",
    "        if len(d_all[elt])==2 :\n",
    "            if d_all[elt][0][9]==1 and d_all[elt][1][8]==1 :\n",
    "                #print(\"cross\",d[elt])\n",
    "                liste_double_cross.append(d_all[elt][0][1]+d_all[elt][1][1])\n",
    "                count_double_cross+=1\n",
    "            else :\n",
    "                liste_double_not_cross.append(d_all[elt][0][1])\n",
    "                liste_double_not_cross.append(d_all[elt][1][1])\n",
    "                count_double_not_cross+=1\n",
    "                #print(d_all[elt])\n",
    "                tot_not_cross.append(elt)\n",
    "        \n",
    "    print(count_cross,count_not_cross,count_double_cross,count_double_not_cross)\n",
    "    return liste_cross,liste_not_cross,liste_double_cross,liste_double_not_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cross_id_old(d_all):\n",
    "    count_cross=0\n",
    "    count_not_cross=0\n",
    "    count_double_cross=0\n",
    "    count_double_not_cross=0\n",
    "    count_double_one_cross=0\n",
    "    liste_cross=defaultdict(list)\n",
    "    liste_not_cross=defaultdict(list)\n",
    "    liste_double_cross=defaultdict(list)\n",
    "    liste_double_not_cross=defaultdict(list)\n",
    "    liste_double_one_cross=defaultdict(list)\n",
    "    tot_not_cross=[]\n",
    "    for elt in d_all :\n",
    "        if len(d_all[elt])==1 :\n",
    "            #print(d[elt])\n",
    "            if d_all[elt][0][0] ==\"start\" :\n",
    "                if d_all[elt][0][9]==1 :\n",
    "                    count_cross+=1\n",
    "                    liste_cross[elt].append(d_all[elt][0][1])\n",
    "                else :\n",
    "                    count_not_cross+=1\n",
    "                    #print(elt,d[elt])\n",
    "                    liste_not_cross[elt].append(d_all[elt][0][1])\n",
    "            if d_all[elt][0][0] ==\"end\" :\n",
    "                if d_all[elt][0][8]==1 :\n",
    "                    count_cross+=1\n",
    "                    liste_cross[elt].append(d_all[elt][0][1])\n",
    "                else :\n",
    "                    count_not_cross+=1 \n",
    "                    liste_not_cross[elt].append(d_all[elt][0][1])\n",
    "        if len(d_all[elt])==2 :\n",
    "            if d_all[elt][0][9]==1 and d_all[elt][1][8]==1 :\n",
    "                #print(\"cross\",d[elt])\n",
    "                liste_double_cross[elt].append(d_all[elt][0][1]+d_all[elt][1][1])\n",
    "                count_double_cross+=1\n",
    "            else :\n",
    "                liste_double_not_cross[elt].append(d_all[elt][0][1])\n",
    "                liste_double_not_cross[elt].append(d_all[elt][1][1])\n",
    "                count_double_not_cross+=1\n",
    "                #print(d_all[elt])\n",
    "                tot_not_cross.append(elt)\n",
    "        \n",
    "    print(count_cross,count_not_cross,count_double_cross,count_double_not_cross)\n",
    "    return liste_cross,liste_not_cross,liste_double_cross,liste_double_not_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cross_id(d_all):\n",
    "    count_cross=0\n",
    "    count_not_cross=0\n",
    "    count_double_cross=0\n",
    "    count_double_not_cross=0\n",
    "    count_double_one_cross=0\n",
    "    liste_cross=defaultdict(list)\n",
    "    liste_not_cross=defaultdict(list)\n",
    "    liste_double_cross=defaultdict(list)\n",
    "    liste_double_not_cross=defaultdict(list)\n",
    "    liste_double_one_cross=defaultdict(list)\n",
    "    tot_not_cross=[]\n",
    "    for elt in d_all :\n",
    "        if len(d_all[elt])==1 :\n",
    "            #print(d[elt])\n",
    "            if d_all[elt][0][0] ==\"start\" :\n",
    "                if d_all[elt][0][9]==1 :\n",
    "                    count_cross+=1\n",
    "                    liste_cross[elt].append(d_all[elt][0][1])\n",
    "            if d_all[elt][0][0] ==\"end\" :\n",
    "                if d_all[elt][0][8]==1 :\n",
    "                    count_cross+=1\n",
    "                    liste_cross[elt].append(d_all[elt][0][1])\n",
    "        if len(d_all[elt])==2 :\n",
    "            if d_all[elt][0][9]==1 and d_all[elt][1][8]==1 :\n",
    "                #print(\"cross\",d[elt])\n",
    "                liste_cross[elt].append(d_all[elt][0][1]+d_all[elt][1][1])\n",
    "                count_double_cross+=1\n",
    "        \n",
    "    return liste_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_liste_insertion(inpt):\n",
    "    lec=csv.reader(open(inpt,\"r\"),delimiter=\"\\t\")\n",
    "    count=0\n",
    "    liste=[]\n",
    "    for elt in lec:\n",
    "        if \"#\" not in elt[0] and \"@\" not in elt[0]:\n",
    "            chrom_inser=re.sub(\"chr\", \"\",elt[0])\n",
    "            if is_valid(elt[4]) :\n",
    "                svseq=elt[4]\n",
    "            else :\n",
    "                parser = elt[7].split(';')\n",
    "                svseq=parser[6].split(\"=\")[1].upper()\n",
    "            pos=int(elt[1])\n",
    "            head=chrom_inser+\"_\"+str(pos)#+\"_\"+str(len(svseq))\n",
    "            liste.append(head)\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(liste,inpt,dic) :\n",
    "    liste_info=set() \n",
    "    lec=csv.reader(open(inpt,\"r\"),delimiter=\",\")\n",
    "    for elt in lec :\n",
    "        heads=re.sub(r'[ \\(\\) \\' ]', \"\",elt[0]).split(\",\")\n",
    "        #print(elt,heads)\n",
    "        head=heads[0]+\"_\"+heads[1]\n",
    "        liste_info=set()\n",
    "        for i in range (1,len(elt)):\n",
    "            liste_info.add(elt[i])\n",
    "        if liste_info and head in liste :\n",
    "            dic[head]=list(liste_info)\n",
    "    return dic\n",
    "def get_other(liste,dic,types) :\n",
    "    count=0\n",
    "    for elt in liste :\n",
    "        if elt not in dic :\n",
    "            #print(elt)\n",
    "            dic[elt]=[types]\n",
    "            count+=1\n",
    "    print(count)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_all_Zook(inpt) :\n",
    "    dic_all=[]\n",
    "    inpt_seq=csv.reader(open(inpt,\"r\"), delimiter=\"\\t\")\n",
    "    for element in inpt_seq :\n",
    "        if \"#\" not in element[0] and \"@\" not in element[0] :\n",
    "            parser = element[7].split(';')\n",
    "            svseq=element[4].upper()\n",
    "            chrom = re.sub(\"chr\", \"\", element[0])\n",
    "            position=int(element[1])\n",
    "            headers=chrom+\"_\"+str(position)+\"_\"+str(len(svseq))\n",
    "            if headers not in dic_all and is_valid(svseq) :\n",
    "                dic_all.append(headers)\n",
    "    return dic_all\n",
    "def get_dic_all_Zook_pass(inpt) :\n",
    "    dic_all=[]\n",
    "    inpt_seq=csv.reader(open(inpt,\"r\"), delimiter=\"\\t\")\n",
    "    for element in inpt_seq :\n",
    "        if \"#\" not in element[0] and \"@\" not in element[0] :\n",
    "            parser = element[7].split(';')\n",
    "            svseq=element[4].upper()\n",
    "            chrom = re.sub(\"chr\", \"\", element[0])\n",
    "            position=int(element[1])\n",
    "            headers=chrom+\"_\"+str(position)+\"_\"+str(len(svseq))\n",
    "            if headers not in dic_all and is_valid(svseq) and element[6]==\"PASS\" :\n",
    "                dic_all.append(headers)\n",
    "    return dic_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_mh(csv_mh) :\n",
    "    lec=csv.reader(open(csv_mh,'r'),delimiter='\\t')\n",
    "    dic=defaultdict()\n",
    "    for elt in lec :\n",
    "        dic[elt[0]]=elt[1]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validity_hom(qpos,tpos,asize,size,types):\n",
    "    if types ==\"start\" :\n",
    "        if qpos+asize>=size-10 and tpos+asize>=size-10 :\n",
    "            return True\n",
    "        else :\n",
    "            return False\n",
    "    if types==\"end\":\n",
    "        if qpos<=10 and tpos<=10 :\n",
    "            return True\n",
    "        else :\n",
    "            return False\n",
    "def get_mh_blat(align_file):\n",
    "    inpts=csv.reader(open(align_file,\"r\"), delimiter='\\t')\n",
    "    dic=defaultdict(list)\n",
    "    i=0\n",
    "    for elt in inpts :\n",
    "        query=elt[9]\n",
    "        target=elt[13]\n",
    "        first_match_size=int(elt[-3].split(\",\")[0])\n",
    "        type_q=elt[9].split(\"_\")[-1]\n",
    "        size_t=int(elt[13].split(\"_\")[-1])\n",
    "        if len(elt[-3].split(\",\"))>2:\n",
    "            first_match_size=int(elt[-3].split(\",\")[0])\n",
    "            last_match_size=int(elt[-3].split(\",\")[-2])\n",
    "            qfirst_match_pos=int(elt[-2].split(\",\")[0])\n",
    "            tfirst_match_pos=int(elt[-1].split(\",\")[0])\n",
    "            qlast_match_pos=int(elt[-2].split(\",\")[-2])\n",
    "            tlast_match_pos=int(elt[-1].split(\",\")[-2])\n",
    "            #print(elt)\n",
    "            #print(first_match_size,last_match_size)\n",
    "            #print(qfirst_match_pos,qlast_match_pos)\n",
    "            #print(tfirst_match_pos,tlast_match_pos)\n",
    "            first=check_validity_hom(qfirst_match_pos,tfirst_match_pos,first_match_size,size_t,type_q)\n",
    "            last=check_validity_hom(qlast_match_pos,tlast_match_pos,last_match_size,size_t,type_q)\n",
    "            #print(first,last)\n",
    "            if type_q==\"start\" and last:\n",
    "                dic[target].append((qlast_match_pos,tlast_match_pos,last_match_size,type_q))\n",
    "            if type_q==\"end\" and first :\n",
    "                dic[target].append((qfirst_match_pos,tfirst_match_pos,first_match_size,type_q))\n",
    "        else :\n",
    "            first_match_size=int(elt[-3].split(\",\")[0])\n",
    "            qfirst_match_pos=int(elt[-2].split(\",\")[0])\n",
    "            tfirst_match_pos=int(elt[-1].split(\",\")[0])\n",
    "            first=check_validity_hom(qfirst_match_pos,tfirst_match_pos,first_match_size,size_t,type_q)\n",
    "            if first:\n",
    "                dic[target].append((qfirst_match_pos,tfirst_match_pos,first_match_size,type_q))\n",
    "            #print(elt)\n",
    "            #print(first_match_size)\n",
    "            #print(qfirst_match_pos)\n",
    "            #print(tfirst_match_pos)\n",
    "            #print(first)\n",
    "    return dic\n",
    "\n",
    "    \n",
    "def check_pos_mh(liste,types) :\n",
    "    first_liste=[]\n",
    "    if types==\"start\" :\n",
    "        size=len(liste)\n",
    "        i=0\n",
    "        for elt in liste :\n",
    "            if i==0 :\n",
    "                first_match=int(elt[0])+int(elt[2])\n",
    "                first_liste=elt\n",
    "                i+=1\n",
    "                continue\n",
    "            else :\n",
    "                other_match=int(elt[0])+int(elt[2])\n",
    "                if other_match> first_match :\n",
    "                    first_match=other_match\n",
    "                    first_liste=elt\n",
    "    if types==\"end\" :\n",
    "        i=0\n",
    "        for elt in liste :\n",
    "            if i==0 :\n",
    "                first_match=int(elt[0])\n",
    "                first_liste=elt\n",
    "                i+=1\n",
    "                continue\n",
    "            else :\n",
    "                other_match=int(elt[0])\n",
    "                if other_match< first_match :\n",
    "                    first_match=other_match\n",
    "                    first_liste=elt\n",
    "    return first_liste\n",
    "def clean_dic(dic):\n",
    "    dic_cleanse=defaultdict(list)\n",
    "    for elt in dic :\n",
    "        liste_start=[]\n",
    "        liste_end=[]\n",
    "        for a in dic[elt] : \n",
    "            if \"start\" in a :\n",
    "                liste_start.append(a)\n",
    "            if \"end\" in a :\n",
    "                liste_end.append(a)\n",
    "        if len(liste_start)==1:\n",
    "            liste_def_start=liste_start[0]\n",
    "            dic_cleanse[elt].append(liste_def_start)\n",
    "        if len(liste_end)==1 :\n",
    "            liste_def_end=liste_end[0]\n",
    "            dic_cleanse[elt].append(liste_def_end)\n",
    "        if len(liste_start)>1 :\n",
    "            liste_def_start=check_pos_mh(liste_start,\"start\")\n",
    "            dic_cleanse[elt].append(liste_def_start)\n",
    "        if len(liste_end)>1 :\n",
    "            liste_def_end=check_pos_mh(liste_end,\"end\")\n",
    "            dic_cleanse[elt].append(liste_def_end)\n",
    "        #break\n",
    "    return dic_cleanse\n",
    "def concatenate_mh(dic_clean) :\n",
    "    dic_size={}\n",
    "    for elt in dic_clean :\n",
    "        head=elt.split(\"_\")[0]+\"_\"+elt.split(\"_\")[1]+\"_\"+elt.split(\"_\")[-1]\n",
    "        if len(dic_clean[elt])==2 :\n",
    "            if dic_clean[elt][-1]==\"start\":\n",
    "                liste_start=dic_clean[elt][0]\n",
    "                liste_end=dic_clean[elt][1]\n",
    "            else :\n",
    "                liste_end=dic_clean[elt][0]\n",
    "                liste_start=dic_clean[elt][1]\n",
    "            if int(liste_start[0])+int(liste_start[2])>=int(elt.split(\"_\")[-1])-10 and int(liste_end[0])<=10 :\n",
    "                if int(liste_start[0]) >= int(liste_end[0]) and int(liste_end[0])+int(liste_end[2])<=int(liste_start[0]) :\n",
    "                    dic_size[head]=int(liste_start[2])+int(liste_end[2])\n",
    "            else :\n",
    "                if int(liste_start[2])> int(liste_end[2]) :\n",
    "                    dic_size[head]=int(liste_start[2])\n",
    "                else :\n",
    "                    dic_size[head]=int(liste_end[2])\n",
    "        elif len(dic_clean[elt])==1 :\n",
    "            dic_size[head]=int(dic_clean[elt][0][2])\n",
    "    return dic_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_type(dic_small,dic_large,dic_all,dic_out) :\n",
    "    dic_convert=get_convert(dic_all)\n",
    "    for elt in dic_large :\n",
    "        #dic_out[elt].append(dic_large[elt][0])\n",
    "        dic_out[elt].append(dic_large[elt])\n",
    "\n",
    "    for a in dic_small :\n",
    "        #print(a)\n",
    "        if a not in dic_all :\n",
    "            head=get_converted(dic_convert,a)\n",
    "        else :\n",
    "            head=a\n",
    "        if head not in dic_out :\n",
    "            dic_out[head].append(dic_small[a])\n",
    "    for v in dic_all :\n",
    "        if v not in dic_out :\n",
    "            dic_out[v].append(0)\n",
    "    return dic_out\n",
    "def Assign_type(dic,liste_type,types) :\n",
    "    tmp=[]\n",
    "    for elt in liste_type :\n",
    "        if elt in dic :\n",
    "            dic[elt].append(types)\n",
    "            tmp.append(dic[elt][0])\n",
    "    #print(tmp)\n",
    "    return dic\n",
    "def get_convert(dic) :\n",
    "    dic_b=defaultdict()\n",
    "    for elt in dic :\n",
    "        head_dic=elt.split(\"_\")[0]+\"_\"+elt.split(\"_\")[1]\n",
    "        dic_b[head_dic]=elt\n",
    "    return dic_b\n",
    "def get_converted(dic,a):\n",
    "    head=a.split(\"_\")[0]+\"_\"+a.split(\"_\")[1]\n",
    "    if head in dic :\n",
    "        return dic[head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def concatenate_dic (dic_1,dic_4):\n",
    "    concat_dic=defaultdict(list)\n",
    "    for elt in dic_4 :\n",
    "        #print(elt)\n",
    "        head=elt.split(\"_\")[0]+\"_\"+elt.split(\"_\")[1]\n",
    "        size=elt.split(\"_\")[2]\n",
    "        #print(elt,dic_1[head])\n",
    "        total=[elt.split(\"_\")[0],elt.split(\"_\")[1],size]+dic_1[head]+dic_4[elt]\n",
    "        #total.append(techno)\n",
    "        #print(total)\n",
    "        \n",
    "        concat_dic[elt]=total\n",
    "    return concat_dic\n",
    "def Assign_techno(dic_all,dic_sr,techno_sr,techno_lr) :\n",
    "    i=0\n",
    "    for elt in dic_all :\n",
    "        if elt in dic_sr :\n",
    "            dic_all[elt].append(techno_sr)\n",
    "            i+=1\n",
    "        else :\n",
    "            dic_all[elt].append(techno_lr)\n",
    "    return dic_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
